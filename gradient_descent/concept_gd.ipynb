{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8194e763",
   "metadata": {},
   "source": [
    " \n",
    "***Gradient Descent — Explanation***\n",
    "\n",
    "*Gradient Descent is an optimization algorithm used to find the best-fit line for a given dataset.\n",
    "The main goal is to minimize the cost function, which measures how well our line fits the data.*\n",
    "\n",
    "-We start by initializing the parameters — the slope (m) and intercept (b) — usually with zeros.\n",
    "Then, through a series of iterations, we continuously update these parameters to reduce the cost.\n",
    "\n",
    "In each iteration:\n",
    "\n",
    "We compute the partial derivatives of the cost function with respect to m and b.\n",
    "\n",
    "These derivatives tell us the direction and magnitude of change needed to minimize the cost.\n",
    "\n",
    "We then update m and b using the formula of Learning Rate\n",
    "\n",
    "With every iteration, the values of m and b are adjusted slightly, and the cost function decreases.\n",
    "After several iterations, the cost stops decreasing — meaning the algorithm has converged to the minimum value.\n",
    "\n",
    "At this point, we have found the optimal values of m and b, and we can use the equation:\n",
    "\n",
    "Y=mX+b\n",
    "\n",
    "to make predictions for new data points."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
